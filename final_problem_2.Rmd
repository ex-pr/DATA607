---
title: "Problem 2 Final"
author: "Daria Dubovskaia"
output:
  html_document:
    toc: true
    toc_depth: 6
---


```{r setup, include=FALSE, results='hide', warning=FALSE, message=FALSE}
library(psych)
library(tidyverse)
library(ggplot2)
library(plotly)
library(GGally)
library(corrplot)
library(ggpubr)
library(pracma)
library(matrixcalc)
library(reshape2)
library(DT)
library(kableExtra)
library(imager)
library(reticulate)
library(raster)
library(nnet)
library(caret)
```

### 2. Final Problem 2. 40 points.
#### 2.1 Go to https://www.kaggle.com/c/digit-recognizer/overview, accept the rules of the competition, and download the data. You will not be required to submit work to Kaggle, but you do need the data. ‘MNIST ("Modified National Institute of Standards and Technology") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.”
The training data frame contains 1460 observations of 81 variables.
```{r}
train <- read.csv('C:/Users/daria/Downloads/train.csv')
```

```{r echo=FALSE}
head(train) %>% 
  kable %>%
  kable_styling("striped", full_width = F) %>% 
 scroll_box(width = "900px", height = "220px")

dim(train)
```

#### 2.2 Using the training.csv file, plot representations of the first 10 images to understand the data format. Go ahead and divide all pixels by 255 to produce values between 0 and 1. (This is equivalent to min-max scaling.) (5 points)
Plot first 10 images:
```{r  warning=FALSE, message=FALSE}
for (image_num in 1:10){
  p <- train[image_num,2:785]
  df1 <- as.data.frame(matrix(nrow=784, ncol=3))
  colnames(df1) <- c("x","y", "value")
  x <- 0
  y <- 1
  for (i in 1:784){
    x <- x+1
    if (x %% 29 == 0) {
      y <- y+1
      x <- 1
    }
    df1[i,] <- c(x,y,p[[i]])
  }
  as.cimg(df1) %>% plot    # image
}
```

We see that the pictures above match the first ten labels from the data frame.
```{r}
train$label[1:10]
```

Now, we divide all pixels by 255 and plot again first ten numbers:
```{r  warning=FALSE, message=FALSE}
train_scaled <- train[,2:ncol(train)]/255
train_scaled$label <- train$label
head(train_scaled) %>% 
  kable %>%
  kable_styling("striped", full_width = F) %>% 
 scroll_box(width = "900px", height = "220px")


for (image_num in 1:10){
  p <- train_scaled[image_num,2:785]
  df1 <- as.data.frame(matrix(nrow=784, ncol=3))
  colnames(df1) <- c("x","y", "value")
  x <- 0
  y <- 1
  for (i in 1:784){
    x <- x+1
    if (x %% 29 == 0) {
      y <- y+1
      x <- 1
    }
    df1[i,] <- c(x,y,p[[i]])
  }
  as.cimg(df1) %>% plot    
}
```


#### 2.3 What is the frequency distribution of the numbers in the dataset?
Digit 1 is the most common in the data frame, followed by 7.
```{r}
train_freq <- train_scaled  %>% 
  group_by(label) %>% 
  summarise(Frequency = n()) 
train_freq 
```

```{r warning=FALSE, message=FALSE}
ggplot(train_freq, aes(x = label,y=Frequency, fill = Frequency)) + 
  geom_histogram(stat='identity') + 
  labs(title = 'Frequency Distribution of Digits, Training Set',
       x = 'Digit') +
  scale_x_continuous(breaks = 0:9) +
  scale_fill_gradient(low = "green", high = "red")
```

#### 2.4 For each number, provide the mean pixel intensity. What does this tell you? (5 points)
The intensity means the brightness. Number 5 has the highest intensity and the darkest picture as the result.
```{r}
instensity <- train_scaled %>% 
  group_by(label) %>% 
  summarise(intensity = sum(train_scaled[2:785])/(n()*784), n= n())
instensity
```

#### 2.5 Reduce the data by using principal components that account for 95% of the variance. How many components did you generate? Use PCA to generate all possible components (100% of the variance). How many components are possible? Why? (5 points)
prcomp() function will help with the Principal Components Analysis:
```{r}
df <- train_scaled

train_prcomp <- prcomp(df)
train_cum <- (cumsum(train_prcomp$sdev^2) / sum(train_prcomp$sdev^2))
```
There are 139 components that account for 95% of the variance
```{r}
plot(train_cum)
cum_95 <- which.max(train_cum  >= .95)
cum_95
```

We hit 100% variance at 705 component. 784 components are possible as there are 784 columns in the training data frame.
```{r}
which.max(train_cum >= 1)
```

#### 2.6 Plot the first 10 images generated by PCA. They will appear to be noise. Why? (5 points)
PCA is used for data reduction, non-useful pixels have been removed. PCA doesn't serve for cleared images.
```{r  warning=FALSE, message=FALSE}

df <- train_prcomp$x[, 1:8] %*% t(train_prcomp$rotation[, 1:8])
df <- scale(df, scale = TRUE, center = TRUE)

for (image_num in 1:10){
  p <- df[image_num,]
  df1 <- as.data.frame(matrix(nrow=784, ncol=3))
  colnames(df1) <- c("x","y", "value")
  x <- 0
  y <- 1
  for (i in 1:784){
    x <- x+1
    if (x %% 29 == 0) {
      y <- y+1
      x <- 1
    }
    df1[i,] <- c(x,y,p[[i]])
  }
  as.cimg(df1) %>% plot    
}
```

#### 2.7 Now, select only those images that have labels that are 8’s. Re-run PCA that accounts for all of the variance (100%). Plot the first 10 images. What do you see? (5 points)
The data frame with 8s only:
```{r}
train_8 <- train %>% 
  filter(label == 8)
train_8 <- train_8 %>% dplyr::select(c(2:785))
dim(train_8)
```
We hit 100% variance at 537 component.
```{r}
train_8_scaled <- train_8/255

train_8_prcomp <- prcomp(train_8_scaled)
train_8_cum <- (cumsum(train_8_prcomp$sdev^2) / sum(train_8_prcomp$sdev^2))

plot(train_8_cum)
cum_1 <- which.max(train_8_cum  >= 1)
cum_1
```
The pictures are clearer for sure.
```{r  warning=FALSE, message=FALSE}

df <- train_8_prcomp$x[, 1:784] %*% t(train_8_prcomp$rotation[, 1:784])
df <- scale(df, scale = TRUE, center = TRUE)

for (image_num in 1:10){
  p <- df[image_num,]
  df1 <- as.data.frame(matrix(nrow=784, ncol=3))
  colnames(df1) <- c("x","y", "value")
  x <- 0
  y <- 1
  for (i in 1:784){
    x <- x+1
    if (x %% 29 == 0) {
      y <- y+1
      x <- 1
    }
    df1[i,] <- c(x,y,p[[i]])
  }
  as.cimg(df1) %>% plot    
}
```

#### 2.8 An incorrect approach to predicting the images would be to build a linear regression model with y as the digit values and X as the pixel matrix. Instead, we can build a multinomial model that classifies the digits. Build a multinomial model on the entirety of the training set. Then provide its classification accuracy (percent correctly identified) as well as a matrix of observed versus forecast values (confusion matrix). This matrix will be a 10 x 10, and correct classifications will be on the diagonal. (10 points.
The multinomial model

```{r}
model <- nnet::multinom(label~., data = train, MaxNWts = 42000)
```

Testing the model:
```{r}
test_df <- train[,2:ncol(train)]
predicted <- predict(model, test_df, type = 'class')
summary(predicted)
```
The 10x10 Confusion Matrix, the accuracy is 89%:
```{r}
train_label <- as.factor(train$label)
confusionMatrix(predicted, train_label)
```



